{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "import tensorboard\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "imgshow(img_grid)\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer.add_image('four_cifar10_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self, hparams, input_size=3 * 32 * 32, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, self.hparams[\"1_hidden\"]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.hparams[\"1_hidden\"], self.hparams[\"2_hidden\"]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.hparams[\"2_hidden\"], self.hparams[\"3_hidden\"]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.hparams[\"3_hidden\"], self.hparams[\"4_hidden\"]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.hparams[\"4_hidden\"], self.hparams[\"5_hidden\"]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.hparams[\"5_hidden\"], num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, _, _, _ = x.shape # flatten the image first\n",
    "        x = x.view(N, -1)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def general_step(self, batch, batch_idx, mode):\n",
    "        images, targets = batch\n",
    "        \n",
    "        #forward pass\n",
    "        out = self.forward(images)\n",
    "        \n",
    "        # loss\n",
    "        loss = F.cross_entropy(out, targets)\n",
    "        \n",
    "        preds = out.argmax(axis=1)\n",
    "        n_correct = (targets == preds).sum()\n",
    "        return loss, n_correct\n",
    "    \n",
    "    def general_end(self, outputs, mode):\n",
    "        # average over all batches aggregated during one epoch\n",
    "        avg_loss = torch.stack([x[mode + '_loss'] for x in outputs]).mean()\n",
    "        total_correct = torch.stack([x[mode + '_n_correct'] for x in outputs]).sum().cpu().numpy()\n",
    "        acc = total_correct / len(self.dataset[mode])\n",
    "        return avg_loss, acc\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, n_correct = self.general_step(batch, batch_idx, \"train\")\n",
    "        # logs \n",
    "        tensorboard_logs = {'loss': loss}\n",
    "        return {'loss': loss, 'train_n_correct': n_correct, 'log': tensorboard_logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, n_correct = self.general_step(batch, batch_idx, \"test\")\n",
    "        return {'val_loss': loss, 'val_n_correct': n_correct}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, n_correct = self.general_step(batch, batch_idx, \"test\")\n",
    "        return {'test_loss': loss, 'test_n_correct': n_correct}\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss, acc = self.general_end(outputs, \"val\")\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'val_loss': avg_loss, 'val_acc': acc, 'log': tensorboard_logs}\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        mean=[0.485, 0.456, 0.406]\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std, inplace=False)])\n",
    "        \n",
    "        cifar10_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "        cifar10_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "        \n",
    "        # train/val split\n",
    "        train_dataset, val_dataset = random_split(cifar10_train, [40000, 10000])\n",
    "            \n",
    "        self.dataset = {}\n",
    "        self.dataset[\"train\"], self.dataset[\"val\"], self.dataset[\"test\"] = train_dataset, val_dataset, cifar10_test\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset[\"train\"], shuffle=True, batch_size=self.hparams[\"batch_size\"])\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset[\"val\"], batch_size=self.hparams[\"batch_size\"])\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.dataset[\"test\"], batch_size=self.hparams[\"batch_size\"])\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.SGD(self.model.parameters(), lr=self.hparams['learning_rate'], momentum=0.9)\n",
    "        return opt\n",
    "        \n",
    "    def visualize_predictions(self, images, preds, targets):\n",
    "        classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "        imgs = images\n",
    "        # determine size of the grid based on batch size\n",
    "        num_rows = torch.tensor(len(images)).float().sqrt().floor()\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        #imgs -= imgs.min(1, keepdim=True)[0]\n",
    "        #imgs /= imgs.max(1, keepdim=True)[0]\n",
    "        for i in range(len(imgs)):\n",
    "            plt.subplot(num_rows, len(imgs) // num_rows + 1, i+1)\n",
    "            img = imgs[i].cpu()\n",
    "            img = img / 2 + 0.5\n",
    "            npimg = img.numpy()\n",
    "            plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "            plt.title(classes[torch.argmax(preds, axis=-1)[i]] + f'\\n[{classes[targets[i]]}]')\n",
    "            plt.axis('off')\n",
    "            \n",
    "        self.logger.experiment.add_figure('predictions', fig, global_step=self.global_step)\n",
    "        \n",
    "    def get_test_acc(self, loader = None):\n",
    "        self.model.eval()\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        if not loader: loader = self.test.data_loader()\n",
    "        \n",
    "        scores = []\n",
    "        labels = []\n",
    "        \n",
    "        for batch in loader:\n",
    "            X, y = batch\n",
    "            X = X.cuda()\n",
    "            score = self.forward(X)\n",
    "            scores.append(score.detach().cpu().numpy())\n",
    "            labels.append(y.detach().cpu().numpy())\n",
    "            \n",
    "        scores = np.concatenate(scores, axis=0)\n",
    "        labels = np.concatenate(labels, axis=0)\n",
    "        \n",
    "        preds = scores.argmax(axis=1)\n",
    "        acc = (labels == preds).mean()\n",
    "        return preds, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"1_hidden\": 1024,\n",
    "    \"2_hidden\": 512,\n",
    "    \"3_hidden\": 256,\n",
    "    \"4_hidden\": 128,\n",
    "    \"5_hidden\": 64,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 5e-4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "model = Net(hparams)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    profiler=True,\n",
    "    max_epochs=70,\n",
    "    gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name     | Type       | Params\n",
      "------------------------------------\n",
      "0  | model    | Sequential | 3 M   \n",
      "1  | model.0  | Linear     | 3 M   \n",
      "2  | model.1  | ReLU       | 0     \n",
      "3  | model.2  | Dropout    | 0     \n",
      "4  | model.3  | Linear     | 524 K \n",
      "5  | model.4  | ReLU       | 0     \n",
      "6  | model.5  | Dropout    | 0     \n",
      "7  | model.6  | Linear     | 131 K \n",
      "8  | model.7  | ReLU       | 0     \n",
      "9  | model.8  | Dropout    | 0     \n",
      "10 | model.9  | Linear     | 32 K  \n",
      "11 | model.10 | ReLU       | 0     \n",
      "12 | model.11 | Dropout    | 0     \n",
      "13 | model.12 | Linear     | 8 K   \n",
      "14 | model.13 | ReLU       | 0     \n",
      "15 | model.14 | Dropout    | 0     \n",
      "16 | model.15 | Linear     | 650   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb65c3eb8d484ba9842b36ae3226ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Profiler Report\n",
      "\r\n",
      "Action              \t|  Mean duration (s)\t|  Total time (s) \r\n",
      "-----------------------------------------------------------------\r\n",
      "on_train_start      \t|  0.015          \t|  0.03           \r\n",
      "on_epoch_start      \t|  0.0015211      \t|  0.108          \r\n",
      "get_train_batch     \t|  0.014767       \t|  656.34         \r\n",
      "on_batch_start      \t|  1.8952e-05     \t|  0.841          \r\n",
      "model_forward       \t|  0.0029894      \t|  132.65         \r\n",
      "model_backward      \t|  0.003138       \t|  139.25         \r\n",
      "on_after_backward   \t|  4.1915e-06     \t|  0.186          \r\n",
      "optimizer_step      \t|  0.0024398      \t|  108.27         \r\n",
      "on_batch_end        \t|  0.0016359      \t|  72.594         \r\n",
      "on_epoch_end        \t|  0.0            \t|  0.0            \r\n",
      "on_train_end        \t|  0.0            \t|  0.0            \r\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation-Accuracy: 70.49%\n"
     ]
    }
   ],
   "source": [
    "_, val_acc = model.get_test_acc(model.val_dataloader())\n",
    "print(\"Validation-Accuracy: {}%\".format(val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
